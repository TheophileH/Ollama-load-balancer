# -----------------------------------------------------------------------------
# LOAD BALANCER IMPLEMENTATION SELECTION
# -----------------------------------------------------------------------------
# Choose between "Rust" (High Performance) or "Python" (Easy to Modify)
# Default: Rust
LB_BUILD_CONTEXT=./Rust_lb
# LB_BUILD_CONTEXT=./Python_lb
LB_DOCKERFILE=Dockerfile
LOG_LEVEL=info

# -----------------------------------------------------------------------------

# Scaling (Number of containers per type)
# Set to 0 to disable a specific vendor (Single-Vendor Mode)
# Example: OLLAMA_AMD_REPLICAS=0 for NVIDIA-only setup
OLLAMA_NVIDIA_REPLICAS=1
OLLAMA_AMD_REPLICAS=1

# Load Balancing Strategy: 'round_robin', 'vram', 'amd', or 'nvidia'
LOAD_BALANCING_STRATEGY=vram
# Enable Model Affinity (Sticky Routing)
# If true, prefers backends that already have the model loaded.
# If model not found, falls back to LOAD_BALANCING_STRATEGY (e.g., vram) for proper placement.
OLLAMA_ENABLE_AFFINITY=false
# If true, strictly follows the strategy. If false, falls back to other if VRAM is insufficient.
ENFORCE_STRATEGY=false

# Total VRAM accessible to each container instance (in MB)
# Leave commented or set to 0 to enable Automatic Detection via nvidia-smi/rocm-smi
# OLLAMA_NVIDIA_VRAM_MB=24576
# OLLAMA_NVIDIA_VRAM_MB=24576
# OLLAMA_AMD_VRAM_MB=49152

# Global Ollama settings passed to the load balancer for reference (not used directly by LB logic but good for consistency)
OLLAMA_MAX_LOADED_MODELS=8
OLLAMA_NUM_PARALLEL=8
OLLAMA_KV_CACHE_TYPE=q8_0
OLLAMA_FLASH_ATTENTION=1

# --- Refactoring: Extracted Configuration ---

# Container Images
OLLAMA_AMD_IMAGE=ollama/ollama:rocm
OLLAMA_NVIDIA_IMAGE=ollama/ollama:latest

# Container Names
OLLAMA_AMD_CONTAINER_NAME=ollama-amd
OLLAMA_NVIDIA_CONTAINER_NAME=ollama-nvidia
OLLAMA_LB_CONTAINER_NAME=load-balancer

# Internal Service Config
OLLAMA_HOST=0.0.0.0:11434
OLLAMA_ORIGINS=*
OLLAMA_MODELS=/root/.ollama/models

# AMD Specific Headers
HSA_OVERRIDE_GFX_VERSION=10.3.0
# ROCR_VISIBLE_DEVICES=0,2
HCC_AMDGPU_TARGET=gfx1030
OLLAMA_CONTEXT_LENGTH=8192

# External Port Mapping
OLLAMA_AMD_PORT=11435
OLLAMA_NVIDIA_PORT=11436

# Volumes
OLLAMA_DATA_VOLUME=ollama
